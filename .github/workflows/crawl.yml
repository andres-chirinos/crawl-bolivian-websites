name: Crawl website

on:
  #schedule:
  #  - cron: "*/15 * * * *"
  workflow_dispatch:
    inputs:
      url:
        description: "URL to crawl"
        required: true
        default: ""
      depth:
        description: "Crawl depth [>=1]"
        required: false
        default: "10"
      scoreType:
        description: "Crawl score type [page, page-spa, {prefix}, host, domain, any, custom]"
        required: false
        default: "prefix"
      runs-on:
        description: "Runner type [{ubuntu-latest}, self-hosted]"
        required: false
        default: "ubuntu-latest"

jobs:
  extract:
    name: Extract
    runs-on: ${{ github.event.inputs.runs-on }}
    env:
      DATA_DIR: ${{ github.workspace }}/data
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Prepare Data
        run: |
          mkdir -p "${DATA_DIR}"
          echo "Preparing data directory at ${DATA_DIR}..."

      - name: Run Crawler
        env:
          URL: ${{ github.event.inputs.url }}
          DEPTH: ${{ github.event.inputs.depth }}
          URL_SLUG: ${{ env.URL_SLUG }}
          SCORE_TYPE: ${{ github.event.inputs.scoreType }}
          DATA_DIR: ${{ env.DATA_DIR }}
        run: |
          echo "DATA_DIR=${DATA_DIR}"
          # ...
          VOLUME_ARG="-v ${DATA_DIR}:/crawls/"
          docker run --rm $VOLUME_ARG webrecorder/browsertrix-crawler crawl \
            # ... otros argumentos ...
            --collection "$URL_SLUG"-"$TIMESTAMP" \
            # ...
            --description "$URL_SLUG - $TIMESTAMP"

      - name: Check artifact content
        run: |
          echo "Checking ${DATA_DIR} content before upload:"
          ls -l "${DATA_DIR}"
          count=$(find "${DATA_DIR}" -type f | wc -l)
          if [[ "$count" -eq 0 ]]; then
            echo "ERROR: No files found in ${DATA_DIR} to upload as artifact."
            exit 1
          fi

      - name: Upload raw data
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.URL_SLUG }}-${{ env.TIMESTAMP }}
          path: ${{ env.DATA_DIR }}/*
          retention-days: ${{ env.GITHUB_ACTIONS_ARTIFACT_DATA_RETENTION_DAYS }}
          if-no-files-found: error

  load:
    name: Load
    needs: extract
    runs-on: ubuntu-latest
    env:
      DATA_DIR: ${{ github.workspace }}/data
    steps:
      - name: Download raw data
        uses: actions/download-artifact@v4
        with:
          name: ${{ env.URL_SLUG }}-${{ env.TIMESTAMP }}
          path: ${{ env.DATA_DIR }}

      - name: Zip raw data
        run: |
          zip -r ${{ env.URL_SLUG }}-${{ env.TIMESTAMP }}.zip "${DATA_DIR}"

      - name: Upload to Google Drive
        uses: willo32/google-drive-upload-action@v1
        with:
          target: ${{ env.URL_SLUG }}-${{ env.TIMESTAMP }}.zip
          credentials: ${{ secrets.GDRIVE_SERVICE_ACCOUNT }}
          parent_folder_id: ${{ env.DRIVE_FOLDER_ID }}
          name: ${{ env.URL_SLUG }}-${{ env.TIMESTAMP }}.zip
          child_folder: ${{ env.URL_SLUG }}
